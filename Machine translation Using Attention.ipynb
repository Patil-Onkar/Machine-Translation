{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Using Attention.ipynb","provenance":[],"mount_file_id":"1UhMa_X4F1KB_NKYlvvVEQ5fxltUSAX3q","authorship_tag":"ABX9TyPnXjuS+M4I21nEyfJj03JM"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DfZ14huOrBNv"},"source":["# Machine Translation\n","  1. Using Encoder Decoder \n","\n","  2. Using word alignment "]},{"cell_type":"code","metadata":{"id":"SwdlLZF9qyJK"},"source":["# Loading Dataset\n","ftr=open('/content/drive/My Drive/Projects/Machine Translation/small_vocab_fr','r')\n","ftrain=ftr.read()\n","ftrain=ftrain.split('\\n')\n","ftr.close()\n","etr=open('/content/drive/My Drive/Projects/Machine Translation/small_vocab_en','r')\n","etrain=etr.read()\n","etrain=etrain.split('\\n')\n","etr.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"Fcim5uQGryic","executionInfo":{"elapsed":3224,"status":"ok","timestamp":1606370742893,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"},"user_tz":-330},"outputId":"abf038d3-5ae6-45f8-b528-7277a6597346"},"source":["# length of the sentences\n","import numpy as np\n","tempf=[]\n","tempe=[]\n","for i in ftrain:\n","  tempf.append(len(i))\n","\n","for i in etrain:\n","  tempe.append(len(i))\n","  \n","print('mean for french sentence ={}, for english={}'.format(np.mean(tempf),np.mean(tempe)))\n","print('STD for french sentence ={}, for english={}'.format(np.std(tempf),np.std(tempe)))\n","\n","import matplotlib.pyplot as plt\n","plt.hist(tempf,bins=10)\n","plt.show()\n","plt.hist(tempe,bins=10)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean for french sentence =70.42748855731497, for english=64.90165456510543\n","STD for french sentence =15.674994266752229, for english=16.42720132640752\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"zpbXtuO4sNYI"},"source":["# Text preprocessing\n","# We will create sequence of 100 words\n","\n","import tensorflow as tf\n","tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=10000,oov_token='<oov>')\n","tokenizer.fit_on_texts(ftrain)\n","fseq=tokenizer.texts_to_sequences(ftrain)\n","fpad=tf.keras.preprocessing.sequence.pad_sequences(\n","    fseq, maxlen=100, dtype='int32', padding='post', truncating='post',\n","    value=0.0)\n","\n","\n","tokenizer1=tf.keras.preprocessing.text.Tokenizer(num_words=10000,oov_token='<oov>')\n","tokenizer1.fit_on_texts(etrain)\n","eseq=tokenizer1.texts_to_sequences(etrain)\n","epad=tf.keras.preprocessing.sequence.pad_sequences(\n","    eseq, maxlen=100, dtype='int32', padding='post', truncating='post',\n","    value=0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKrqWIVnsk_Z"},"source":["# Finished with data preprocessing\n","train_input=fpad[:130000]\n","train_output=epad[:130000]\n","train_input=train_input.reshape((130000,100))\n","train_output=train_output.reshape((130000,100))\n","\n","test_input=fpad[130000:]\n","test_output=epad[130000:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuqYnOJvtLVX"},"source":["Implementing the paper's archetacture without the alignment layer that is without attention. \n","\n","Paper- NEURAL MACHINE TRANSLATION\n","BY JOINTLY LEARNING TO ALIGN AND TRANSLATE\n","by - Dzmitry Bahdanau\n","\n","\n","  1. The Encoder -Decoder architecture is as follows-\n","\n","  Encoder = Input --> Embedding with 16 vector size ---> Bi-Directional lstm with 100 units.\n","    \n","  Decoder = Output --> Bidirectional lstm 100 units--> softmax Dense\n","    "]},{"cell_type":"code","metadata":{"id":"s7jb-18H0MDP"},"source":["import tensorflow as tf\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VS2gJFSxtHh3"},"source":["tf.keras.backend.clear_session()\n","class Enc(tf.keras.Model):\n","  def __init__(self):\n","    super(Enc,self).__init__()\n","    self.emb=tf.keras.layers.Embedding(346,16)\n","    self.inp=tf.keras.Input(shape=(100))\n","    self.bilstm=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True))\n","\n","  def call(self,inputs):\n","    #x=self.inp(inputs)\n","    x=self.emb(inputs)\n","    x=self.bilstm(x)\n","    return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pq3O0Q1hy04_"},"source":["class Dec(tf.keras.Model):\n","  def __init__(self):\n","    super(Dec,self).__init__()\n","    self.bilstm=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True))\n","    self.d1=tf.keras.layers.Dense(201,activation='sigmoid')\n","\n","  def call(self,inputs):\n","    x=self.bilstm(inputs)\n","    x=self.d1(x)\n","    return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IB_Vh8BATZS"},"source":["class EncDec(tf.keras.Model):\n","  def __init__(self):\n","    super(EncDec,self).__init__()\n","    self.enc=Enc()\n","    self.dec=Dec()\n","  def call(self,inputs):\n","    x=self.enc(inputs)\n","    x=self.dec(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_uw7pjdaBTlt"},"source":["model=EncDec()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RsYqzPQBk4T"},"source":["model.build(input_shape=(64,100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOreA6h5Bvcr","executionInfo":{"elapsed":1165,"status":"ok","timestamp":1606369197352,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"},"user_tz":-330},"outputId":"02a47535-3ab4-440b-dea1-f7b0154f366e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"enc_dec\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","enc (Enc)                    multiple                  99136     \n","_________________________________________________________________\n","dec (Dec)                    multiple                  281201    \n","=================================================================\n","Total params: 380,337\n","Trainable params: 380,337\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dgfyM1VyC17z"},"source":["model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n","               metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MAnnuMJvDgQk","outputId":"0d99d799-48ff-45dc-f752-87e02e5c3fe2"},"source":["model.fit(train_input,train_output,batch_size=64,epochs=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","2032/2032 [==============================] - 1177s 579ms/step - loss: 0.6092 - accuracy: 0.9043\n","Epoch 2/5\n","2032/2032 [==============================] - 1169s 575ms/step - loss: 0.2615 - accuracy: 0.9289\n","Epoch 3/5\n","2032/2032 [==============================] - 1180s 581ms/step - loss: 1.1632 - accuracy: 0.9087\n","Epoch 4/5\n","2032/2032 [==============================] - 1176s 579ms/step - loss: 1.9241 - accuracy: 0.8819\n","Epoch 5/5\n","2032/2032 [==============================] - 1160s 571ms/step - loss: 1.9241 - accuracy: 0.8819\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc4783c5d30>"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nxy-IA4nDoxL","executionInfo":{"elapsed":1772,"status":"ok","timestamp":1606370756535,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"},"user_tz":-330},"outputId":"c41d61f2-6d3f-460c-b2ef-df807f277a53"},"source":["tf.keras.backend.clear_session()\n","\n","inp=tf.keras.Input(shape=(100))\n","l1=tf.keras.layers.Embedding(346,16)(inp)\n","l2=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True))(l1)\n","l3=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True))(l2)\n","out=tf.keras.layers.Dense(201,activation='sigmoid')(l3)\n","#out=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1,activation='softmax'))(l)\n","\n","model2=tf.keras.Model(inp,out)\n","model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 100, 16)           5536      \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 100, 200)          93600     \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 100, 200)          240800    \n","_________________________________________________________________\n","dense (Dense)                (None, 100, 201)          40401     \n","=================================================================\n","Total params: 380,337\n","Trainable params: 380,337\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WYLNeMGsJpvL"},"source":["model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n","               metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"iAla7-e6J0-T","executionInfo":{"elapsed":1205756,"status":"error","timestamp":1606371976018,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"},"user_tz":-330},"outputId":"d89c61cf-7182-4126-d2c4-2c38cbe403a7"},"source":["model2.fit(train_input,train_output,batch_size=64,epochs=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","2032/2032 [==============================] - 1182s 581ms/step - loss: 1.9003 - accuracy: 0.8870\n","Epoch 2/5\n","  30/2032 [..............................] - ETA: 18:34 - loss: 1.8287 - accuracy: 0.8865"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-704f3b04a439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"bLCzfAmcmJW9"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6diAGvMJ4TC"},"source":["time_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(29))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Noxe-0ZemPbO"},"source":["def rnn_model(input_dim, units=20, activation='relu', output_dim=29):\n","    \"\"\" Build a recurrent network for speech \n","    \"\"\"\n","    # Main acoustic input\n","    input_data = Input(name='the_input', shape=(None, input_dim))\n","    # Add recurrent layer\n","    simp_rnn = GRU(units, activation=activation,\n","        return_sequences=True, implementation=2, name='rnn')(input_data)\n","    # TODO: Add batch normalization \n","    bn_rnn = BatchNormalization()(simp_rnn)\n","    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n","    time_dense = TimeDistributed(Dense(29))(bn_rnn)\n","    # Add softmax activation layer\n","    y_pred = Activation('softmax', name='softmax')(time_dense)\n","    # Specify the model\n","    model = Model(inputs=input_data, outputs=y_pred)\n","    model.output_length = lambda x: x\n","    print(model.summary())\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYdFBYrpmwL0","executionInfo":{"status":"ok","timestamp":1607083177717,"user_tz":-330,"elapsed":1243,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}},"outputId":"27032213-e0af-471e-ce9f-4f7496680830"},"source":["model_1 = rnn_model(input_dim=161, # change to 13 if you would like to use MFCC features\n","                    units=200,\n","                    activation='relu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","the_input (InputLayer)       [(None, None, 161)]       0         \n","_________________________________________________________________\n","rnn (GRU)                    (None, None, 200)         217800    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, None, 200)         800       \n","_________________________________________________________________\n","time_distributed_2 (TimeDist (None, None, 29)          5829      \n","_________________________________________________________________\n","softmax (Activation)         (None, None, 29)          0         \n","=================================================================\n","Total params: 224,429\n","Trainable params: 224,029\n","Non-trainable params: 400\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZgofcqHknt3Z","executionInfo":{"status":"ok","timestamp":1607142094607,"user_tz":-330,"elapsed":3929,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}}},"source":["import keras"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW-7ePNtnvjf","executionInfo":{"status":"ok","timestamp":1607142094611,"user_tz":-330,"elapsed":3154,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}}},"source":["from keras import backend as K\n","from keras.models import Model\n","from keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n","    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNp_u3gwZvGq","executionInfo":{"status":"ok","timestamp":1607146658645,"user_tz":-330,"elapsed":1282,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}}},"source":["def cnn_output_length(input_length, filter_size, border_mode, stride,\n","                       dilation=1):\n","    \"\"\" Compute the length of the output sequence after 1D convolution along\n","        time. Note that this function is in line with the function used in\n","        Convolution1D class from Keras.\n","    Params:\n","        input_length (int): Length of the input sequence.\n","        filter_size (int): Width of the convolution kernel.\n","        border_mode (str): Only support `same` or `valid`.\n","        stride (int): Stride size used in 1D convolution.\n","        dilation (int)\n","    \"\"\"\n","    if input_length is None:\n","        return None\n","    assert border_mode in {'same', 'valid'}\n","    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n","    if border_mode == 'same':\n","        output_length = input_length\n","    elif border_mode == 'valid':\n","        output_length = input_length - dilated_filter_size + 1\n","    return (output_length + stride - 1) // stride"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPrljhKSnxVP","executionInfo":{"status":"ok","timestamp":1607146694360,"user_tz":-330,"elapsed":1173,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}}},"source":["def final_model (input_dim, filters, kernel_size, conv_stride,\n","    conv_border_mode, units, output_dim=29):\n","    # Main acoustic input\n","    input_data = Input(name='the_input', shape=(None, input_dim))\n","    # convolutional layer\n","    conv_1d = Conv1D(filters, kernel_size, \n","                     strides=conv_stride, \n","                     padding=conv_border_mode,\n","                     activation='relu',\n","                     name='conv1d')(input_data)\n","    # batch normalization\n","    bn_cnn = BatchNormalization(name='bn_conv_1d')(conv_1d)\n","    # Add a recurrent layer\n","    rnn1 = GRU(units, activation='relu',\n","        return_sequences=True, implementation=2)(bn_cnn)\n","    # TODO: Add batch normalization\n","    bn_rnn = BatchNormalization()(rnn1)\n","    \n","    # Add one more RNN\n","    rnn2 = GRU(units, activation='relu',\n","        return_sequences=True, implementation=2)(bn_rnn)\n","    \n","    # Add batch normalization 2 \n","    \n","    bn_rnn1 = BatchNormalization()(rnn2)\n","    \n","    \n","    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n","    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn1)\n","    \n","    # Add softmax activation layer\n","    y_pred = Activation('softmax', name='softmax')(time_dense)\n","    \n","    # Specify the model\n","    model = Model(inputs=input_data, outputs=y_pred)\n","    model.output_length = lambda x: cnn_output_length(\n","        x, kernel_size, conv_border_mode, conv_stride)\n","    print(model.summary())\n","    return model"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kp5AezbfIqVO","executionInfo":{"status":"ok","timestamp":1607146701332,"user_tz":-330,"elapsed":1394,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}},"outputId":"5a41e457-e55d-4576-e029-5335d2f5f05a"},"source":["fm=final_model(input_dim=161, # change to 13 if you would like to use MFCC features\n","                        filters=200,\n","                        kernel_size=11, \n","                        conv_stride=2,\n","                        conv_border_mode='valid',\n","                        units=200)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","the_input (InputLayer)       [(None, None, 161)]       0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, None, 200)         354400    \n","_________________________________________________________________\n","bn_conv_1d (BatchNormalizati (None, None, 200)         800       \n","_________________________________________________________________\n","gru_5 (GRU)                  (None, None, 200)         241200    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, None, 200)         800       \n","_________________________________________________________________\n","gru_6 (GRU)                  (None, None, 200)         241200    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, None, 200)         800       \n","_________________________________________________________________\n","time_distributed_2 (TimeDist (None, None, 29)          5829      \n","_________________________________________________________________\n","softmax (Activation)         (None, None, 29)          0         \n","=================================================================\n","Total params: 845,029\n","Trainable params: 843,829\n","Non-trainable params: 1,200\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uYGu8TFAIwcD","executionInfo":{"status":"ok","timestamp":1607147357110,"user_tz":-330,"elapsed":1418,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}}},"source":["def final_model1 (input_dim, filters, kernel_size, conv_stride,\n","    conv_border_mode, units, output_dim=29):\n","    # Main acoustic input\n","    input_data = Input(name='the_input', shape=(None, input_dim))\n","    # convolutional layer\n","    conv_1d1 = Conv1D(50, 3, \n","                     strides=1, \n","                     padding=conv_border_mode,\n","                     activation='relu',\n","                     dilation_rate=1)(input_data)\n","    # batch normalization\n","    bn_cnn1 = BatchNormalization()(conv_1d1)\n","    # Add a recurrent layer\n","    conv_1d2 = Conv1D(100, 3, \n","                     strides=1, \n","                     padding=conv_border_mode,\n","                     activation='relu',\n","                     dilation_rate=2)(bn_cnn1)\n","    bn_cnn2 = BatchNormalization()(conv_1d2)\n","    # Add a recurrent layer\n","    conv_1d3 = Conv1D(150, 3, \n","                     strides=1, \n","                     padding=conv_border_mode,\n","                     activation='relu',\n","                     dilation_rate=4)(bn_cnn2)\n","\n","    bn_cnn3 = BatchNormalization()(conv_1d3)\n","    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n","    time_dense = TimeDistributed(Dense(output_dim))(bn_cnn3)\n","    \n","    # Add softmax activation layer\n","    y_pred = Activation('softmax', name='softmax')(time_dense)\n","    \n","    # Specify the model\n","    model = Model(inputs=input_data, outputs=y_pred)\n","    model.output_length = lambda x: cnn_output_length(\n","        x, 150, conv_border_mode, conv_stride=1)\n","    print(model.summary())\n","    return model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mj63PaMZiM4","executionInfo":{"status":"ok","timestamp":1607147357659,"user_tz":-330,"elapsed":1391,"user":{"displayName":"onkar patil","photoUrl":"","userId":"06386359679562619491"}},"outputId":"a2857188-6aaa-40a0-f83d-a50ddfb0998a"},"source":["fm=final_model1(input_dim=161, # change to 13 if you would like to use MFCC features\n","                        filters=200,\n","                        kernel_size=11, \n","                        conv_stride=1,\n","                        conv_border_mode='valid',\n","                        units=200)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Model: \"functional_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","the_input (InputLayer)       [(None, None, 161)]       0         \n","_________________________________________________________________\n","conv1d_6 (Conv1D)            (None, None, 50)          24200     \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, None, 50)          200       \n","_________________________________________________________________\n","conv1d_7 (Conv1D)            (None, None, 100)         15100     \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, None, 100)         400       \n","_________________________________________________________________\n","conv1d_8 (Conv1D)            (None, None, 150)         45150     \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, None, 150)         600       \n","_________________________________________________________________\n","time_distributed_5 (TimeDist (None, None, 29)          4379      \n","_________________________________________________________________\n","softmax (Activation)         (None, None, 29)          0         \n","=================================================================\n","Total params: 90,029\n","Trainable params: 89,429\n","Non-trainable params: 600\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZO7wojRhcRmQ"},"source":[""],"execution_count":null,"outputs":[]}]}